{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117ad202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from numpy.random import randint\n",
    "\n",
    "import time\n",
    "import shutil\n",
    "import torchvision.transforms\n",
    "import torch.utils.data.dataloader\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "\n",
    "from models import i3d\n",
    "# from dataset import I3DDataSet\n",
    "# from transforms import *\n",
    "# from opts import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4479e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoRecord(object):\n",
    "    def __init__(self, row):\n",
    "        self._data = row\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return self._data[0]\n",
    "\n",
    "    @property\n",
    "    def num_frames(self):\n",
    "        return int(self._data[1])\n",
    "\n",
    "    @property\n",
    "    def label(self):\n",
    "        return int(self._data[2])\n",
    "\n",
    "\n",
    "class I3DDataSet(data.Dataset):\n",
    "    def __init__(self, root_path, list_file, clip_length=64, frame_size=(320, 240),\n",
    "                 modality='RGB', image_tmpl='img_{:05d}.jpg',\n",
    "                 transform=None, random_shift=True, test_mode=False):\n",
    "        self.root_path = root_path\n",
    "        self.list_file = list_file\n",
    "        self.clip_length = clip_length\n",
    "        self.frame_size = frame_size\n",
    "        self.modality = modality\n",
    "        self.image_tmpl = image_tmpl\n",
    "        self.transform = transform\n",
    "        self.random_shift = random_shift\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "        self._parse_list()\n",
    "\n",
    "    def _load_image(self, directory, idx):\n",
    "        root_path = os.path.join(self.root_path, 'rawframes/')  # ../data/ucf101/rawframes/\n",
    "        directory = os.path.join(root_path, directory)\n",
    "\n",
    "        if self.modality == 'RGB' or self.modality == 'RGBDiff':\n",
    "            return [Image.open(os.path.join(directory, self.image_tmpl.format(idx))).convert('RGB')]\n",
    "        elif self.modality == 'Flow':\n",
    "            x_img = Image.open(os.path.join(directory, self.image_tmpl.format('x', idx))).convert('L')\n",
    "            y_img = Image.open(os.path.join(directory, self.image_tmpl.format('y', idx))).convert('L')\n",
    "\n",
    "            return [x_img, y_img]\n",
    "\n",
    "    def _parse_list(self):\n",
    "        self.video_list = [VideoRecord(x.strip().split(' ')) for x in\n",
    "                           open(os.path.join(self.root_path, self.list_file))]\n",
    "\n",
    "    def _sample_indices(self, record):\n",
    "        if not self.test_mode and self.random_shift:\n",
    "            average_duration = record.num_frames // self.clip_length\n",
    "            if average_duration > 0:\n",
    "                offsets = np.sort(\n",
    "                    np.multiply(list(range(self.clip_length)), average_duration) + randint(average_duration,\n",
    "                                                                                           size=self.clip_length))\n",
    "            else:\n",
    "                offsets = np.sort(randint(record.num_frames, size=self.clip_length))\n",
    "        else:\n",
    "            tick = record.num_frames / float(self.clip_length)\n",
    "            offsets = np.array([int(tick / 2.0 + tick * x) for x in range(self.clip_length)])\n",
    "        return offsets + 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        record = self.video_list[index]\n",
    "        indices = self._sample_indices(record)\n",
    "        return self.get(record, indices)\n",
    "\n",
    "    def get(self, record, indices):\n",
    "        images = list()\n",
    "        for index in indices:\n",
    "            img = self._load_image(record.path, int(index))\n",
    "            images.extend(img)\n",
    "        process_data = self.transform(images)\n",
    "        return process_data, record.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764b62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f055473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_prec1 = 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    global args, best_prec1\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.dataset == 'ucf101':\n",
    "        num_classes = 101\n",
    "    elif args.dataset == 'hmdb51':\n",
    "        num_classes = 51\n",
    "    elif args.dataset == 'kinetics':\n",
    "        num_classes = 400\n",
    "    else:\n",
    "        raise ValueError('Unknown dataset ' + args.dataset)\n",
    "\n",
    "    model = getattr(i3d, args.arch)(modality=args.modality, num_classes=num_classes,\n",
    "                                    dropout_ratio=args.dropout)\n",
    "\n",
    "    crop_size = args.input_size\n",
    "    scale_size = args.input_size * 256 // 224\n",
    "    input_mean = [0.485, 0.456, 0.406]\n",
    "    input_std = [0.229, 0.224, 0.225]\n",
    "    if args.modality == 'Flow':\n",
    "        input_mean = [0.5]\n",
    "        input_std = [np.mean(input_std)]\n",
    "\n",
    "    train_augmentation = get_augmentation(args.modality, args.input_size)\n",
    "\n",
    "    model = torch.nn.DataParallel(model, device_ids=args.gpus).cuda()\n",
    "\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.evaluate, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # Data loading code\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        I3DDataSet(args.root_path, args.train_list, clip_length=args.clip_length, modality=args.modality,\n",
    "                   image_tmpl=\"img_{:05d}.jpg\" if args.modality == \"RGB\" else args.flow_prefix + \"{}_{:05d}.jpg\",\n",
    "                   transform=torchvision.transforms.Compose([\n",
    "                       train_augmentation,\n",
    "                       ToNumpyNDArray(),\n",
    "                       ToTorchFormatTensor(),\n",
    "                       GroupNormalize(input_mean, input_std),\n",
    "                   ])),\n",
    "        batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        I3DDataSet(args.root_path, args.val_list, clip_length=args.clip_length, modality=args.modality,\n",
    "                   image_tmpl=\"img_{:05d}.jpg\" if args.modality == \"RGB\" else args.flow_prefix + \"{}_{:05d}.jpg\",\n",
    "                   random_shift=False,\n",
    "                   transform=torchvision.transforms.Compose([\n",
    "                       GroupScale(int(scale_size)),\n",
    "                       GroupCenterCrop(crop_size),\n",
    "                       ToNumpyNDArray(),\n",
    "                       ToTorchFormatTensor(),\n",
    "                       GroupNormalize(input_mean, input_std),\n",
    "                   ])),\n",
    "        batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    if args.loss_type == 'nll':\n",
    "        criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown loss type\")\n",
    "\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=args.lr, momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    if args.evaluate:\n",
    "        validate(val_loader, model, criterion, 0)\n",
    "        return\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        adjust_learning_rate(optimizer, epoch, args.lr_steps)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        if (epoch + 1) % args.eval_freq == 0 or epoch == args.epochs - 1:\n",
    "            prec1 = validate(val_loader, model, criterion, (epoch + 1) * len(train_loader))\n",
    "\n",
    "            # remember best prec@1 and save checkpoint\n",
    "            is_best = prec1 > best_prec1\n",
    "            best_prec1 = max(prec1, best_prec1)\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': args.arch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_prec1': best_prec1,\n",
    "            }, is_best)\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.cuda()\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if args.clip_gradient is not None:\n",
    "            total_norm = clip_grad_norm(model.parameters(), args.clip_gradient)\n",
    "            if total_norm > args.clip_gradient:\n",
    "                print(\"clipping gradient: {} with coef {}\".format(total_norm, args.clip_gradient / total_norm))\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print(('Epoch: [{0}][{1}/{2}], lr: {lr:.5f}\\t'\n",
    "                   'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                   'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                   'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                   'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                   'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses, top1=top1, top5=top5, lr=optimizer.param_groups[-1]['lr'])))\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, iter, logger=None):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            target = target.cuda()\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec1.item(), input.size(0))\n",
    "            top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                print(('Test: [{0}/{1}]\\t'\n",
    "                       'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                       'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                       'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                       'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                    i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                    top1=top1, top5=top5)))\n",
    "\n",
    "    print(('Testing Results: Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Loss {loss.avg:.5f}'\n",
    "           .format(top1=top1, top5=top5, loss=losses)))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    filename = '_'.join((args.snapshot_pref, args.modality.lower(), filename))\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        best_name = '_'.join((args.snapshot_pref, args.modality.lower(), 'model_best.pth.tar'))\n",
    "        shutil.copyfile(filename, best_name)\n",
    "\n",
    "\n",
    "def get_augmentation(modality, input_size):\n",
    "    if modality == 'RGB':\n",
    "        return torchvision.transforms.Compose([GroupMultiScaleCrop(input_size, [1, .875, .75, .66]),\n",
    "                                               GroupRandomHorizontalFlip(is_flow=False)])\n",
    "    elif modality == 'Flow':\n",
    "        return torchvision.transforms.Compose([GroupMultiScaleCrop(input_size, [1, .875, .75]),\n",
    "                                               GroupRandomHorizontalFlip(is_flow=True)])\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, lr_steps):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    decay = 0.1 ** (sum(epoch >= np.array(lr_steps)))\n",
    "    lr = args.lr * decay\n",
    "    decay = args.weight_decay\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        param_group['weight_decay'] = decay\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541e2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b673b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4f439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd551e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4527ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
